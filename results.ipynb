{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCaYsWcDx2WqaysuRphzkd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7wxQmlw2xpA",
        "outputId": "d3c9f048-98fd-4c7d-a5a5-e852befa486f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/Shareddrives/gdrive/datasets/thesis/results /content"
      ],
      "metadata": {
        "id": "_WTorIE-3LEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_latex(df, caption=\"\", label=\"\", width_scale=0.5):\n",
        "  \"\"\"Converts a Pandas DataFrame to LaTeX format with adjustable width.\"\"\"\n",
        "  latex_str = \"\\\\begin{table}[htbp]\\n\\\\centering\\n\\\\resizebox{\" + str(width_scale) + \"\\\\linewidth}{!}{\\n\"\n",
        "  latex_str += df.to_latex(index=False, caption=caption, label=label)\n",
        "  latex_str += \"\\n}\\n\\\\end{table}\"\n",
        "  return latex_str"
      ],
      "metadata": {
        "id": "G2aQlwPN83g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def df_to_latex(df, caption=\"\", label=\"\"):\n",
        "  \"\"\"Converts a Pandas DataFrame to LaTeX format.\"\"\"\n",
        "  latex_str = df.to_latex(index=False, caption=caption, label=label)\n",
        "  return latex_str"
      ],
      "metadata": {
        "id": "R1aUiJMg21kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_stats_by_model(df):\n",
        "  \"\"\"Groups the DataFrame by 'model' and calculates median, min, and max for numerical columns.\"\"\"\n",
        "  return df.groupby('Model', as_index=False).agg(['median', 'min', 'max']).drop('Random Seed', axis=1)"
      ],
      "metadata": {
        "id": "CxQrIzwODXVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import wilcoxon\n",
        "import pandas as pd\n",
        "\n",
        "def wilcoxon_test(csv_file1, csv_file2, metric, alpha=0.05):\n",
        "    # Чтение данных из CSV файлов\n",
        "    df1 = pd.read_csv(csv_file1)\n",
        "    df2 = pd.read_csv(csv_file2)\n",
        "\n",
        "    # Извлечение выбранной метрики\n",
        "    metric1 = df1[metric]\n",
        "    metric2 = df2[metric]\n",
        "\n",
        "    # Применение теста Уилкоксона\n",
        "    stat, p_value = wilcoxon(metric1, metric2)\n",
        "\n",
        "    # Вывод результатов теста\n",
        "    print(f'Wilcoxon test statistic: {stat}')\n",
        "    print(f'P-value: {p_value}')\n",
        "\n",
        "    # Проверка на статистическую значимость\n",
        "    if p_value < alpha:\n",
        "        print(f'The difference between the models for {metric} is statistically significant (p < {alpha}).')\n",
        "    else:\n",
        "        print(f'The difference between the models for {metric} is not statistically significant (p >= {alpha}).')\n",
        "\n",
        "    return stat, p_value"
      ],
      "metadata": {
        "id": "UEj1D5Q2PlpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import wilcoxon\n",
        "import pandas as pd\n",
        "import itertools\n",
        "\n",
        "def wilcoxon_compare_models(paths1, paths2, metric, alpha=0.05):\n",
        "    # Получаем имена моделей из путей\n",
        "    models = ['cb', 'lr', 'rf']\n",
        "\n",
        "    # Цикл по каждой модели\n",
        "    for model in models:\n",
        "        # Фильтрация путей для текущей модели\n",
        "        file1 = [path for path in paths1 if model in path][0]\n",
        "        file2 = [path for path in paths2 if model in path][0]\n",
        "\n",
        "        print(f\"\\nComparing {model.upper()} models for metric: {metric}\")\n",
        "\n",
        "        # Чтение данных из файлов\n",
        "        df1 = pd.read_csv(file1)\n",
        "        df2 = pd.read_csv(file2)\n",
        "\n",
        "        # Извлечение выбранной метрики\n",
        "        metric1 = df1[metric]\n",
        "        metric2 = df2[metric]\n",
        "\n",
        "        # Применение теста Уилкоксона\n",
        "        stat, p_value = wilcoxon(metric1, metric2)\n",
        "\n",
        "        # Вывод результатов теста\n",
        "        print(f'Wilcoxon test statistic: {stat}')\n",
        "        print(f'P-value: {p_value}')\n",
        "\n",
        "        # Проверка на статистическую значимость\n",
        "        if p_value < alpha:\n",
        "            print(f'The difference between the {model.upper()} models for {metric} is statistically significant (p < {alpha}).')\n",
        "        else:\n",
        "            print(f'The difference between the {model.upper()} models for {metric} is not statistically significant (p >= {alpha}).')\n",
        "\n",
        "# Пример использования\n",
        "paths1 = [\n",
        "    '/content/results/results-tfidf/cb_classifier_results_finance.csv',\n",
        "    '/content/results/results-tfidf/lr_classifier_results_finance.csv',\n",
        "    '/content/results/results-tfidf/rf_classifier_results_finance.csv'\n",
        "]\n",
        "\n",
        "paths2 = [\n",
        "    '/content/results/results-tfidf/cb_classifier_results_finance_news.csv',\n",
        "    '/content/results/results-tfidf/lr_classifier_results_finance_news.csv',\n",
        "    '/content/results/results-tfidf/rf_classifier_results_finance_news.csv'\n",
        "]\n",
        "\n",
        "paths3 = [\n",
        "    '/content/results/results-sbert/cb_classifier_results_finance_news.csv',\n",
        "    '/content/results/results-sbert/lr_classifier_results_finance_news.csv',\n",
        "    '/content/results/results-sbert/rf_classifier_results_finance_news.csv'\n",
        "]\n",
        "\n",
        "# Вызываем функцию для сравнения по метрике 'Accuracy'\n",
        "print(\"Comparing models trained on Finance only with models trained on Finance and News (TF-IDF Preprocessing)\")\n",
        "wilcoxon_compare_models(paths1, paths2, 'Accuracy')\n",
        "print(\"==========================\")\n",
        "print()\n",
        "print(\"Comparing models trained on Finance only with models trained on Finance and News (SBERT MiniLM V2 Preprocessing)\")\n",
        "wilcoxon_compare_models(paths1, paths3, 'Accuracy')\n",
        "print(\"Comparing models trained on Finance only with models trained on Finance and News (TF-IDF Preprocessing) and News (SBERT MiniLM V2 Preprocessing)\")\n",
        "print(\"==========================\")\n",
        "print()\n",
        "wilcoxon_compare_models(paths2, paths3, 'Accuracy')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVn04ImfQgcF",
        "outputId": "74bad2f4-d657-4968-e494-c8f1c1848f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing models trained on Finance only with models trained on Finance and News (TF-IDF Preprocessing)\n",
            "\n",
            "Comparing CB models for metric: Accuracy\n",
            "Wilcoxon test statistic: 7.0\n",
            "P-value: 0.00115966796875\n",
            "The difference between the CB models for Accuracy is statistically significant (p < 0.05).\n",
            "\n",
            "Comparing LR models for metric: Accuracy\n",
            "Wilcoxon test statistic: 0.0\n",
            "P-value: 6.103515625e-05\n",
            "The difference between the LR models for Accuracy is statistically significant (p < 0.05).\n",
            "\n",
            "Comparing RF models for metric: Accuracy\n",
            "Wilcoxon test statistic: 0.0\n",
            "P-value: 6.103515625e-05\n",
            "The difference between the RF models for Accuracy is statistically significant (p < 0.05).\n",
            "==========================\n",
            "\n",
            "Comparing models trained on Finance only with models trained on Finance and News (SBERT MiniLM V2 Preprocessing)\n",
            "\n",
            "Comparing CB models for metric: Accuracy\n",
            "Wilcoxon test statistic: 2.0\n",
            "P-value: 0.00018310546875\n",
            "The difference between the CB models for Accuracy is statistically significant (p < 0.05).\n",
            "\n",
            "Comparing LR models for metric: Accuracy\n",
            "Wilcoxon test statistic: 0.0\n",
            "P-value: 6.103515625e-05\n",
            "The difference between the LR models for Accuracy is statistically significant (p < 0.05).\n",
            "\n",
            "Comparing RF models for metric: Accuracy\n",
            "Wilcoxon test statistic: 0.0\n",
            "P-value: 6.103515625e-05\n",
            "The difference between the RF models for Accuracy is statistically significant (p < 0.05).\n",
            "Comparing models trained on Finance only with models trained on Finance and News (TF-IDF Preprocessing) and News (SBERT MiniLM V2 Preprocessing)\n",
            "==========================\n",
            "\n",
            "\n",
            "Comparing CB models for metric: Accuracy\n",
            "Wilcoxon test statistic: 40.0\n",
            "P-value: 0.7005293624084632\n",
            "The difference between the CB models for Accuracy is not statistically significant (p >= 0.05).\n",
            "\n",
            "Comparing LR models for metric: Accuracy\n",
            "Wilcoxon test statistic: 0.0\n",
            "P-value: 6.103515625e-05\n",
            "The difference between the LR models for Accuracy is statistically significant (p < 0.05).\n",
            "\n",
            "Comparing RF models for metric: Accuracy\n",
            "Wilcoxon test statistic: 42.0\n",
            "P-value: 0.33026123046875\n",
            "The difference between the RF models for Accuracy is not statistically significant (p >= 0.05).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paths = ['/content/results/results-tfidf/cb_classifier_results_finance.csv',\n",
        "         '/content/results/results-tfidf/lr_classifier_results_finance.csv',\n",
        "         '/content/results/results-tfidf/rf_classifier_results_finance.csv']\n",
        "\n",
        "# paths = ['/content/results/results-tfidf/cb_classifier_results_finance_news.csv',\n",
        "#          '/content/results/results-tfidf/lr_classifier_results_finance_news.csv',\n",
        "#          '/content/results/results-tfidf/rf_classifier_results_finance_news.csv']\n",
        "\n",
        "# paths = ['/content/results/results-sbert/cb_classifier_results_finance_news.csv',\n",
        "#          '/content/results/results-sbert/lr_classifier_results_finance_news.csv',\n",
        "#          '/content/results/results-sbert/rf_classifier_results_finance_news.csv']\n",
        "\n",
        "df = pd.DataFrame()\n",
        "\n",
        "for path in paths:\n",
        "    sun_df = pd.read_csv(path)\n",
        "    df = pd.concat([df, sun_df])\n",
        "\n",
        "# latex = df_to_latex(calculate_stats_by_model(df), caption=\"Finance only models' metrics results\")\n",
        "latex = df_to_latex(calculate_stats_by_model(df), caption=\"Finance only models' metrics results\")\n",
        "\n",
        "with open('results-no-news.tex', 'w') as f:\n",
        "    f.write(latex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVTJ1h_i3npw",
        "outputId": "cb4bb3c5-69bf-4d5a-926b-d3cfa3d2aa10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-21079c5b8bed>:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
            "  return df.groupby('Model', as_index=False).agg(['median', 'min', 'max']).drop('Random Seed', axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paths = ['/content/results/results-tfidf/cb_classifier_results_finance_news.csv',\n",
        "         '/content/results/results-tfidf/lr_classifier_results_finance_news.csv',\n",
        "         '/content/results/results-tfidf/rf_classifier_results_finance_news.csv']\n",
        "\n",
        "df = pd.DataFrame()\n",
        "\n",
        "for path in paths:\n",
        "    sun_df = pd.read_csv(path)\n",
        "    df = pd.concat([df, sun_df])\n",
        "\n",
        "latex = df_to_latex(calculate_stats_by_model(df), caption=\"Finance and News with TF-IDF preprocessing metrics results\")\n",
        "\n",
        "with open('results-news-tfidf.tex', 'w') as f:\n",
        "    f.write(latex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PJtESsQ_yZq",
        "outputId": "0d951331-4bce-418e-d041-01813e937c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-21079c5b8bed>:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
            "  return df.groupby('Model', as_index=False).agg(['median', 'min', 'max']).drop('Random Seed', axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paths = ['/content/results/results-sbert/cb_classifier_results_finance_news.csv',\n",
        "         '/content/results/results-sbert/lr_classifier_results_finance_news.csv',\n",
        "         '/content/results/results-sbert/rf_classifier_results_finance_news.csv']\n",
        "\n",
        "df = pd.DataFrame()\n",
        "\n",
        "for path in paths:\n",
        "    sun_df = pd.read_csv(path)\n",
        "    df = pd.concat([df, sun_df])\n",
        "\n",
        "latex = df_to_latex(calculate_stats_by_model(df), caption=\"Finance and News with SBERT preprocessing metrics results\")\n",
        "\n",
        "with open('results-news-sbert.tex', 'w') as f:\n",
        "    f.write(latex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ACenkvC4AC8",
        "outputId": "688a38ac-f75d-4b6e-941a-2aa3994b94b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-21079c5b8bed>:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
            "  return df.groupby('Model', as_index=False).agg(['median', 'min', 'max']).drop('Random Seed', axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_eIQe8mN4KHz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}